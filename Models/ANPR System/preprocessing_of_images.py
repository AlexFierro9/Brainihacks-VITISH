# -*- coding: utf-8 -*-
"""kavach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o-VbE4cID2k-KRnjKn_trQuk5p2VzD07
"""

# Commented out IPython magic to ensure Python compatibility.
import cv2
import numpy as np
import matplotlib.pyplot as plt
import skimage.exposure as skie
# %matplotlib inline

img = plt.imread('/content/number_plate.jpeg')[..., 0]

def show(img):
    # Display the image.
    fig, (ax1, ax2) = plt.subplots(1, 2,
                                   figsize=(12, 3))

    ax1.imshow(img, cmap=plt.cm.gray)
    ax1.set_axis_off()

    # Display the histogram.
    ax2.hist(img.ravel(), lw=0, bins=256)
    ax2.set_xlim(0, img.max())
    ax2.set_yticks([])

    plt.show()

show(img)

show(skie.rescale_intensity(
    img, in_range=(0.4, .95), out_range=(0, 1)))

show(skie.equalize_adapthist(img))

"""blurring images:"""

#coverting to spatial domain
def plot_sine_1D(amp,wavelength,phase):
    x = np.arange(-500, 501, 1)
    y = np.sin((2 * np.pi * x / wavelength)+phase)
    plt.plot(x, y)
    plt.show()
plot_sine_1D(1,300,0)

def compute_fft(f):
    ft = np.fft.fft2(f)
    ft = np.fft.fftshift(ft)
    return ft

f,ax = plt.subplots(1,2,figsize=(15,20))
ax = ax.flatten()
im = cv2.imread('/content/number_plate.jpeg',-1)
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
ax[0].imshow(im,cmap='gray')
ax[1].imshow(20*np.log(abs(compute_fft(im))),cmap='gray')

# Plotting image and its blurred version
f,ax = plt.subplots(1,2,figsize=(15,20))
ax = ax.flatten()
im = cv2.imread('/content/number_plate.jpeg',-1)
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im_blur = cv2.GaussianBlur(im,(7,7), 5, 5)
ax[0].imshow(im,cmap='gray')
ax[1].imshow(im_blur,cmap='gray')

def gaussian_filter(kernel_size,img,sigma=1, muu=0):
    x, y = np.meshgrid(np.linspace(-1, 1, kernel_size),
                       np.linspace(-1, 1, kernel_size))
    dst = np.sqrt(x**2+y**2)
    normal = 1/(((2*np.pi)**0.5)*sigma)
    gauss = np.exp(-((dst-muu)**2 / (2.0 * sigma**2))) * normal
    gauss = np.pad(gauss, [(0, img.shape[0] - gauss.shape[0]), (0, img.shape[1] - gauss.shape[1])], 'constant')
    return gauss

def fft_deblur(img,kernel_size,kernel_sigma=5,factor='wiener',const=0.002):
    gauss = gaussian_filter(kernel_size,img,kernel_sigma)
    img_fft = np.fft.fft2(img)
    gauss_fft = np.fft.fft2(gauss)
    weiner_factor = 1 / (1+(const/np.abs(gauss_fft)**2))
    if factor!='wiener':
        weiner_factor = factor
    recon = img_fft/gauss_fft
    recon*=weiner_factor
    recon = np.abs(np.fft.ifft2(recon))
    return recon

recon = fft_deblur(im_blur,7,5,factor=1)
plt.subplots(figsize=(10,8))
plt.imshow(recon,cmap='gray')

noise = np.random.rand(100,100)
noise_fft = np.fft.fft2(noise)
noise_fft = np.fft.fftshift(noise_fft)
f,ax = plt.subplots(1,2,figsize=(15,20))
ax = ax.flatten()
ax[0].imshow(noise,cmap='gray')
ax[0].set_title('Original Image')
ax[1].imshow(20*np.log(abs(compute_fft(noise_fft))),cmap='gray')
ax[1].set_title('Fourier Transform')

gauss = gaussian_filter(7,im,5)
gauss_fft = np.fft.fft2(gauss)
gauss_fft = np.fft.fftshift(gauss_fft)
f,ax = plt.subplots(1,2,figsize=(15,20))
ax = ax.flatten()
ax[0].imshow(gauss,cmap='gray')
ax[0].set_title('Original Image')
ax[1].imshow(np.abs(gauss_fft),cmap='gray')
ax[1].set_title('Fourier Transform')

"""method 2:"""

!pip install pylops

# Import the necessary libraries
from PIL import Image
from numpy import asarray
 
 
# load the image and convert into
# numpy array
im = Image.open('/content/blurryimage.png')
 
# asarray() class is used to convert
# PIL images into NumPy arrays
numpydata = asarray(img)
 
# <class 'numpy.ndarray'>
print(type(numpydata))
 
#  shape
print(numpydata.shape)

import cv2
import argparse
import glob

# Commented out IPython magic to ensure Python compatibility.
# open cv packege
import cv2
from cv2 import IMREAD_COLOR,IMREAD_UNCHANGED

# useful packeges
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns

# statistic packeges
from scipy.ndimage import variance
from skimage import io
from skimage.color import rgb2gray
from skimage.filters import laplace
from skimage.transform import resize
# %matplotlib inline

def variance_of_laplacian(img2):
    # compute the Laplacian of the image and then return the focus
    # measure, which is simply the variance of the Laplacian
    gray = cv2.cvtColor(img2, cv2.COLOR_RGB2BGR)
    return cv2.Laplacian(gray, cv2.CV_64F).var()

def BGR2RGB(BGR_img):
    # turning BGR pixel color to RGB
    rgb_image = cv2.cvtColor(BGR_img, cv2.COLOR_BGR2RGB)
    return rgb_image

def blurrinesDetection(directories,threshold):
    columns = 3
    rows = len(directories)//2
    fig=plt.figure(figsize=(5*columns, 4*rows))
    for i,directory in enumerate(directories):
        fig.add_subplot(rows, columns, i+1)
        img = cv2.imread(directory)
        text = "Not Blurry"
        # if the focus measure is less than the supplied threshold,
        # then the image should be considered "blurry
        fm = variance_of_laplacian(img)
        if fm < threshold:
            text = "Blurry"
        rgb_img = BGR2RGB(img)
        cv2.putText(rgb_img, "{}: {:.2f}".format(text, fm), (10, 30),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        plt.imshow(rgb_img)
    plt.show()

directories = ['/content/Number_plate_blurred.png'.format(i) for i in range(8,10)]
blurrinesDetection(directories,300)

"""#deblurring the image"""

from scipy.ndimage import variance
from skimage import io
from skimage.color import rgb2gray
from skimage.filters import laplace
from skimage.transform import resize

def laplaceEdgeVariance(path):
    # Load image
    img = cv2.imread(path)

    # Resize image
    img = resize(img, (400, 600))
    
    # Gray-Scale change
    img = rgb2gray(img)

    # Edge detection
    edge_laplace = laplace(img, ksize=3)
    
    return [variance(edge_laplace),np.amax(edge_laplace)]

humen_detection_of_blurriness = [1,1,0,0,0,0,0,0,1]
Thermal = [0,0,0,0,0,0,0,1,1]
df = pd.DataFrame(list(zip(directories, humen_detection_of_blurriness,Thermal)), 
               columns =['Directory', 'Vision Mode','Thermal'])
df['Vision Mode'].replace({0:'Sharp',1:'Blurry'},inplace=True)
df['Thermal'].replace({0:'No',1:'Yes'},inplace=True)
df

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/megvii-research/NAFNet
# %cd NAFNet

!pip install -r requirements.txt
!pip install --upgrade --no-cache-dir gdown
!python3 setup.py develop --no_cuda_ext

import gdown
gdown.download('https://drive.google.com/uc?id=14D4V4raNYIOhETfcuuLI3bGLB-OYIv6X', "./experiments/pretrained_models/", quiet=False)

import torch

from basicsr.models import create_model
from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite
from basicsr.utils.options import parse
import numpy as np
import cv2
import matplotlib.pyplot as plt

def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img
def img2tensor(img, bgr2rgb=False, float32=True):
    img = img.astype(np.float32) / 255.
    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)

def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1) 
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('NAFNet output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)

def single_image_inference(model, img, save_path):
      model.feed_data(data={'lq': img.unsqueeze(dim=0)})

      if model.opt['val'].get('grids', False):
          model.grids()

      model.test()

      if model.opt['val'].get('grids', False):
          model.grids_inverse()

      visuals = model.get_current_visuals()
      sr_img = tensor2img([visuals['result']])
      imwrite(sr_img, save_path)

#creating the model
opt_path = 'options/test/REDS/NAFNet-width64.yml'
opt = parse(opt_path, is_train=False)
opt['dist'] = False
NAFNet = create_model(opt)

input_path1 = '/content/deblur1.png'
output_path1 = '/content/unblurred1.jpg'

img_input = imread(input_path1)
inp = img2tensor(img_input)
single_image_inference(NAFNet, inp, output_path1)
img_output = imread(output_path1)
display(img_input, img_output)

!sudo apt install tesseract-ocr
!pip install pytesseract

#importing libraries
import pytesseract
import shutil
import os
import random
import PIL
from PIL import Image

image_path='/content/unblurred.jpg'
extractedInformation = pytesseract.image_to_string(Image.open(image_path))
print(extractedInformation)

image = cv2.imread('/content/unblurred.jpg', flags=cv2.IMREAD_COLOR)

!pip install easyocr

import easyocr
reader = easyocr.Reader(['hi','en'])

im = PIL.Image.open("/content/unblurred.jpg")
im

import cv2
 
src = cv2.imread('/content/unblurred.jpg', cv2.IMREAD_UNCHANGED)

#percent by which the image is resized
scale_percent = 100

#calculate the 70 percent of original dimensions
width = int(src.shape[1] * scale_percent / 100)
height = int(src.shape[0] * scale_percent / 100)

# dsize
dsize = (width, height)

# resize image
output = cv2.resize(src, dsize)

cv2.imwrite('/content/unblurred_resized.jpg',output)

bounds=reader.readtext('/content/unblurred_resized.jpg')
bounds